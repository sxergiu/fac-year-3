{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sxergiu/fac-year-3/blob/main/IPR/IPR3_Laboratory_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Recurrent neural networks"
      ],
      "metadata": {
        "id": "5jhyhiSJVqWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we add the necessary imports and set a constant seed for the random number generator in PyTorch."
      ],
      "metadata": {
        "id": "suoLpSoTs4Vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import os\n",
        "import requests\n",
        "import re\n",
        "import collections\n",
        "import random\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "\n",
        "torch.manual_seed(42);"
      ],
      "metadata": {
        "id": "wBjOO9kPDJMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text is one of the most popular examples of sequence data. For example, an article can be simply viewed as a sequence of words, or even a sequence of characters. The common preprocessing steps for text, usually, are:\n",
        "\n",
        "1. Load text as strings into memory.\n",
        "1. Split strings into tokens (e.g., words and characters).\n",
        "1. Build a table of vocabulary to map the split tokens to numerical indices.\n",
        "1. Convert text into sequences of numerical indices so they can be manipulated by models easily.\n",
        "\n",
        "To get started we load text from H. G. Wells' [*The Time Machine*](http://www.gutenberg.org/ebooks/35). This is a fairly small corpus of just over $30000$ words, but, for the purpose of what we want to illustrate, this is just fine. More realistic document collections contain many billions of words. The `read_time_machine()` function reads the dataset into a list of text lines, where each line is a string. For simplicity, here we ignore punctuation and capitalization."
      ],
      "metadata": {
        "id": "xPKDgFrzth4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download(url, cache_dir=os.path.join('..', 'data')):\n",
        "    \"\"\"Download a file, return the local filename.\"\"\"\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
        "    if os.path.exists(fname):\n",
        "        with open(fname, 'rb') as f:\n",
        "            while True:\n",
        "                data = f.read(1048576)\n",
        "                if not data:\n",
        "                    break\n",
        "        return fname\n",
        "    print(f'Downloading {fname} from {url}...')\n",
        "    r = requests.get(url, stream=True, verify=True)\n",
        "    with open(fname, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "    return fname"
      ],
      "metadata": {
        "id": "B1Q50eDmDD_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_time_machine():\n",
        "    \"\"\"Load the time machine dataset into a list of text lines.\"\"\"\n",
        "    with open(download('http://d2l-data.s3-accelerate.amazonaws.com/timemachine.txt'), 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n",
        "\n",
        "lines = read_time_machine()\n",
        "print(f'# text lines: {len(lines)}')\n",
        "print(lines[0])\n",
        "print(lines[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PMDPiHuCc-h",
        "outputId": "f20fbc24-27bf-4bcf-cb8e-00395e9df5b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# text lines: 3221\n",
            "the time machine by h g wells\n",
            "twinkled and his usually pale face was flushed and animated the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following `tokenize()` function takes a list (`lines`) as the input, where each element is a text sequence (e.g., a text line). Each text sequence is split into a list of tokens. A *token* is the basic unit in text. In the end, a list of token lists are returned, where each token is a string."
      ],
      "metadata": {
        "id": "5T--FND7uYhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(lines, token='word'):\n",
        "    \"\"\"Split text lines into word or character tokens.\"\"\"\n",
        "    if token == 'word':\n",
        "        return [line.split() for line in lines]\n",
        "    elif token == 'char':\n",
        "        return [list(line) for line in lines]\n",
        "    else:\n",
        "        print('ERROR: unknown token type: ' + token)\n",
        "\n",
        "tokens = tokenize(lines)\n",
        "for i in range(11):\n",
        "    print(tokens[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NHosKb7CW_c",
        "outputId": "eab38285-3f87-4ba4-bf9c-2dbd84517cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "['i']\n",
            "[]\n",
            "[]\n",
            "['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him']\n",
            "['was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and']\n",
            "['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The string type of the token is inconvenient to be used by models, which take numerical inputs. Now let us build a dictionary, often called *vocabulary* as well, to map string tokens into numerical indices starting from $0$. To do so, we first count the unique tokens in all the documents from the training set, namely a *corpus*, and then assign a numerical index to each unique token according to its frequency. Rarely appeared tokens are often removed to reduce the complexity. Any token that does not exist in the corpus or has been removed is mapped into a special unknown token “&lt;unk&gt;”. We optionally add a list of reserved tokens, such as “&lt;pad&gt;” for padding, “&lt;bos&gt;” to represent the beginning of a sequence, and “&lt;eos&gt;” for the end of a sequence."
      ],
      "metadata": {
        "id": "Kp9vPYJ5upVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "    \"\"\"Vocabulary for text.\"\"\"\n",
        "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
        "        if tokens is None:\n",
        "            tokens = []\n",
        "        if reserved_tokens is None:\n",
        "            reserved_tokens = []\n",
        "        # Sort according to frequencies\n",
        "        counter = count_corpus(tokens)\n",
        "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
        "                                   reverse=True)\n",
        "        # The index for the unknown token is 0\n",
        "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
        "        self.token_to_idx = {token: idx\n",
        "                             for idx, token in enumerate(self.idx_to_token)}\n",
        "        for token, freq in self._token_freqs:\n",
        "            if freq < min_freq:\n",
        "                break\n",
        "            if token not in self.token_to_idx:\n",
        "                self.idx_to_token.append(token)\n",
        "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_to_token)\n",
        "\n",
        "    def __getitem__(self, tokens):\n",
        "        if not isinstance(tokens, (list, tuple)):\n",
        "            return self.token_to_idx.get(tokens, self.unk)\n",
        "        return [self.__getitem__(token) for token in tokens]\n",
        "\n",
        "    def to_tokens(self, indices):\n",
        "        if not isinstance(indices, (list, tuple)):\n",
        "            return self.idx_to_token[indices]\n",
        "        return [self.idx_to_token[index] for index in indices]\n",
        "\n",
        "    @property\n",
        "    def unk(self):  # Index for the unknown token\n",
        "        return 0\n",
        "\n",
        "    @property\n",
        "    def token_freqs(self):  # Token frequencies\n",
        "        return self._token_freqs\n",
        "\n",
        "def count_corpus(tokens):\n",
        "    \"\"\"Count token frequencies.\"\"\"\n",
        "    # Here `tokens` is a 1D list or 2D list\n",
        "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
        "        # Flatten a list of token lists into a list of tokens\n",
        "        tokens = [token for line in tokens for token in line]\n",
        "    return collections.Counter(tokens)"
      ],
      "metadata": {
        "id": "vwnOjpzzCNjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We construct a vocabulary using the `time machine` dataset as the corpus. Then, we print the first few frequent tokens with their indices."
      ],
      "metadata": {
        "id": "CNTQL-FkvUPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Vocab(tokens)\n",
        "print(list(vocab.token_to_idx.items())[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSfvoEGkvTqK",
        "outputId": "b40ecff2-2902-4ee5-a402-f4506f74e937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('<unk>', 0), ('the', 1), ('i', 2), ('and', 3), ('of', 4), ('a', 5), ('to', 6), ('was', 7), ('in', 8), ('that', 9)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can convert each text line into a list of numerical indices."
      ],
      "metadata": {
        "id": "qfbL1e35vm3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [0, 10]:\n",
        "    print('words:', tokens[i])\n",
        "    print('indices:', vocab[tokens[i]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWJfWY2Nvp-z",
        "outputId": "3b674830-0c0d-4d8a-b1e0-e5d3da570ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words: ['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n",
            "indices: [1, 19, 50, 40, 2183, 2184, 400]\n",
            "words: ['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']\n",
            "indices: [2186, 3, 25, 1044, 362, 113, 7, 1421, 3, 1045, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the above functions, we package everything into the `load_corpus_time_machine()` function, which returns `corpus`, a list of token indices, and `vocab`, the vocabulary of the time machine corpus.\n",
        "The modifications we did here are:\n",
        "(i) we tokenize text into characters, not words, to simplify the later training;\n",
        "(ii) `corpus` is a single list, not a list of token lists, since each text line in the `time machine` dataset is not necessarily a sentence or a paragraph."
      ],
      "metadata": {
        "id": "Zvg1oSBrvunW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_corpus_time_machine(max_tokens=-1):\n",
        "    \"\"\"Return token indices and the vocabulary of the time machine dataset.\"\"\"\n",
        "    lines = read_time_machine()\n",
        "    tokens = tokenize(lines, 'char')\n",
        "    vocab = Vocab(tokens)\n",
        "    # Since each text line in the time machine dataset is not necessarily a\n",
        "    # sentence or a paragraph, flatten all the text lines into a single list\n",
        "    corpus = [vocab[token] for line in tokens for token in line]\n",
        "    if max_tokens > 0:\n",
        "        corpus = corpus[:max_tokens]\n",
        "    return corpus, vocab\n",
        "\n",
        "corpus, vocab = load_corpus_time_machine()\n",
        "len(corpus), len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99Br8poOCEUr",
        "outputId": "3ee42ffe-acf3-4b6a-80b5-c0fb9a864f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(170580, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can ensure that the subsequences from two adjacent mini-batches during iteration are adjacent on the original sequence. This strategy preserves the order of split subsequences when iterating over mini-batches, hence is called *sequential partitioning*."
      ],
      "metadata": {
        "id": "pVE_0JDIwbZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_data_iter_sequential(corpus, batch_size, num_steps):\n",
        "    \"\"\"Generate a mini-batch of subsequences using sequential partitioning.\"\"\"\n",
        "    # Start with a random offset to partition a sequence\n",
        "    offset = random.randint(0, num_steps)\n",
        "    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
        "    Xs = torch.tensor(corpus[offset: offset + num_tokens])\n",
        "    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n",
        "    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n",
        "    num_batches = Xs.shape[1] // num_steps\n",
        "    for i in range(0, num_steps * num_batches, num_steps):\n",
        "        X = Xs[:, i: i + num_steps]\n",
        "        Y = Ys[:, i: i + num_steps]\n",
        "        yield X, Y"
      ],
      "metadata": {
        "id": "9SrdiwSTBsxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us manually generate a sequence from $0$ to $34$. We assume that the batch size and number of time steps are $2$ and $5$, respectively. This means that we can generate $\\lfloor (35 - 1) / 5 \\rfloor= 6$ feature-label subsequence pairs. With a mini-batch size of $2$, we only get $3$ mini-batches.\n",
        "\n",
        "Let us print features `X` and labels `Y` for each mini-batch of subsequences read by sequential partitioning. Note that the subsequences from two adjacent mini-batches during iteration are indeed adjacent in the original sequence."
      ],
      "metadata": {
        "id": "-v28nktDxC9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_seq = list(range(35))\n",
        "for X, Y in seq_data_iter_sequential(my_seq, batch_size=2, num_steps=5):\n",
        "    print('X: ', X, '\\nY:', Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKUPBqXyxQZT",
        "outputId": "9bcd7d7e-c14a-4fc5-a871-c50554638419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:  tensor([[ 2,  3,  4,  5,  6],\n",
            "        [18, 19, 20, 21, 22]]) \n",
            "Y: tensor([[ 3,  4,  5,  6,  7],\n",
            "        [19, 20, 21, 22, 23]])\n",
            "X:  tensor([[ 7,  8,  9, 10, 11],\n",
            "        [23, 24, 25, 26, 27]]) \n",
            "Y: tensor([[ 8,  9, 10, 11, 12],\n",
            "        [24, 25, 26, 27, 28]])\n",
            "X:  tensor([[12, 13, 14, 15, 16],\n",
            "        [28, 29, 30, 31, 32]]) \n",
            "Y: tensor([[13, 14, 15, 16, 17],\n",
            "        [29, 30, 31, 32, 33]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we wrap the above two sampling functions to a class, so that we can use it as a data iterator later."
      ],
      "metadata": {
        "id": "nsvQaQ7bx3FB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SeqDataLoader:\n",
        "    \"\"\"An iterator to load sequence data.\"\"\"\n",
        "    def __init__(self, batch_size, num_steps, max_tokens):\n",
        "        self.corpus, self.vocab = load_corpus_time_machine(max_tokens)\n",
        "        self.batch_size, self.num_steps = batch_size, num_steps\n",
        "\n",
        "    def __iter__(self):\n",
        "        return seq_data_iter_sequential(self.corpus, self.batch_size, self.num_steps)"
      ],
      "metadata": {
        "id": "O5pXs-IoBHtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we define a function `load_data_time_machine()` that returns both the data iterator and the vocabulary, so we can use it similarly as other functions with the `load_data` prefix, such as `load_data_fashion_mnist()` defined in *Laboratory 3*."
      ],
      "metadata": {
        "id": "9nes6WA9yJf8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxWxgOcS_auI"
      },
      "outputs": [],
      "source": [
        "def load_data_time_machine(batch_size, num_steps, max_tokens=10000):\n",
        "    \"\"\"Return the iterator and the vocabulary of the time machine dataset.\"\"\"\n",
        "    data_iter = SeqDataLoader(\n",
        "        batch_size, num_steps, max_tokens)\n",
        "    return data_iter, data_iter.vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to implement a language model with RNNs, we use functions provided by the high-level APIs of PyTorch. We begin by reading the `time machine` dataset."
      ],
      "metadata": {
        "id": "743mlIXwzCyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, num_steps = 32, 35\n",
        "train_iter, vocab = load_data_time_machine(batch_size, num_steps)"
      ],
      "metadata": {
        "id": "vmWtkkDzE5im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "High-level APIs provide implementations of recurrent neural networks. We construct the recurrent neural network layer `rnn_layer` with a single hidden layer and $256$ hidden units."
      ],
      "metadata": {
        "id": "rdUS7dvKzdN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_hiddens = 256\n",
        "rnn_layer = nn.RNN(len(vocab), num_hiddens)"
      ],
      "metadata": {
        "id": "a6OUsw2KE8_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use a tensor to initialize the hidden state, whose shape is\n",
        "(number of hidden layers, batch size, number of hidden units)."
      ],
      "metadata": {
        "id": "WHKr4eqQz5ET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state = torch.zeros((1, batch_size, num_hiddens))\n",
        "state.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMga5UNiFFZZ",
        "outputId": "611145e9-704c-41a9-a453-185808088938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With a hidden state and an input, we can compute the output with the updated hidden state. It should be emphasized that the \"output\" (`Y`) of `rnn_layer` does *not* involve computation of output layers: it refers to the hidden state at *each* time step, and they can be used as the input to the subsequent output layer."
      ],
      "metadata": {
        "id": "qmQH4slC0ALm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(size=(num_steps, batch_size, len(vocab)))\n",
        "Y, state_new = rnn_layer(X, state)\n",
        "Y.shape, state_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kaj6poo5FHbX",
        "outputId": "e3e6ecc8-c466-44d5-c5fe-327b64a7fef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([35, 32, 256]), torch.Size([1, 32, 256]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that each token is represented as a numerical index in `train_iter`. Feeding these indices directly to a neural network might make it hard to learn. We often represent each token as a more expressive feature vector. The easiest representation is called *one-hot encoding*.\n",
        "\n",
        "In a nutshell, we map each index to a different unit vector: assume that the number of different tokens in the vocabulary is $N$ (`len(vocab)`) and the token indices range from $0$ to $N-1$. If the index of a token is the integer $i$, then we create a vector of all $0$s with a length of $N$ and set the element at position $i$ to $1$. This vector is the one-hot vector of the original token. The one-hot vectors with indices $0$ and $2$ are shown below."
      ],
      "metadata": {
        "id": "oIfiIdBeItzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "F.one_hot(torch.tensor([0, 2]), len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xwERALMJJUN",
        "outputId": "19869bfa-488b-4d59-ce01-61ba0fcf6e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0],\n",
              "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of the mini-batch that we sample each time is (batch size, number of time steps). The `F.one_hot()` function transforms such a mini-batch into a three-dimensional tensor, where the last dimension equals to the vocabulary size (`len(vocab)`). We often transpose the input, so that we will obtain an output of shape (number of time steps, batch size, vocabulary size). This will allow us to more conveniently loop through the outermost dimension for updating hidden states of a mini-batch, time step by time step."
      ],
      "metadata": {
        "id": "mrM4MzXrJM96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.arange(10).reshape((2, 5))\n",
        "F.one_hot(X.T, 28).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR5Lhs-YJv4V",
        "outputId": "1b622d02-64f3-40b9-ffbb-0ad8232ccec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 2, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define an `RNNModel` class for a complete RNN model. Note that `rnn_layer` only contains the hidden recurrent layers, so we need to create a separate output layer."
      ],
      "metadata": {
        "id": "GYM1tweo0OP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    \"\"\"The RNN model.\"\"\"\n",
        "    def __init__(self, rnn_layer, vocab_size, **kwargs):\n",
        "        super(RNNModel, self).__init__(**kwargs)\n",
        "        self.rnn = rnn_layer\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_hiddens = self.rnn.hidden_size\n",
        "        self.linear = nn.Linear(self.num_hiddens, self.vocab_size)\n",
        "\n",
        "    def forward(self, inputs, state):\n",
        "        X = F.one_hot(inputs.T.long(), self.vocab_size)\n",
        "        X = X.to(torch.float32)\n",
        "        Y, state = self.rnn(X, state)\n",
        "        # The fully connected layer will first change the shape of `Y` to\n",
        "        # (`num_steps` * `batch_size`, `num_hiddens`). Its output shape is\n",
        "        # (`num_steps` * `batch_size`, `vocab_size`).\n",
        "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n",
        "        return output, state\n",
        "\n",
        "    def begin_state(self, device, batch_size=1):\n",
        "        if not isinstance(self.rnn, nn.LSTM):\n",
        "            # `nn.GRU` takes a tensor as hidden state\n",
        "            return  torch.zeros((self.rnn.num_layers,\n",
        "                                 batch_size, self.num_hiddens),\n",
        "                                 device=device)\n",
        "        else:\n",
        "            # `nn.LSTM` takes a tuple of hidden states\n",
        "            return (torch.zeros((\n",
        "                self.rnn.num_layers,\n",
        "                batch_size, self.num_hiddens), device=device),\n",
        "                    torch.zeros((\n",
        "                        self.rnn.num_layers,\n",
        "                        batch_size, self.num_hiddens), device=device))"
      ],
      "metadata": {
        "id": "_cPsMX3tFKI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us first define the prediction function to generate new characters following\n",
        "the user-provided `prefix`, which is a string containing several characters.  When looping through these beginning characters in `prefix`, we keep passing the hidden state to the next time step without generating any output. This is called the *warm-up* period, during which the model updates itself (e.g., update the hidden state), but does not make predictions. After the warm-up period, the hidden state is generally better than its initialized value at the beginning. So we generate the predicted characters and emit them."
      ],
      "metadata": {
        "id": "EhL7VPtM0uPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(prefix, num_preds, net, vocab, device):\n",
        "    \"\"\"Generate new characters following the `prefix`.\"\"\"\n",
        "    state = net.begin_state(batch_size=1, device=device)\n",
        "    outputs = [vocab[prefix[0]]]\n",
        "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
        "    for y in prefix[1:]:  # Warm-up period\n",
        "        _, state = net(get_input(), state)\n",
        "        outputs.append(vocab[y])\n",
        "    for _ in range(num_preds):  # Predict `num_preds` steps\n",
        "        y, state = net(get_input(), state)\n",
        "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
        "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
      ],
      "metadata": {
        "id": "qhqJVv_XFlIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can test the `predict()` function. We specify the prefix as `time traveller` and have it generate $10$ additional characters. Given that we have not trained the network yet, i.e., the model has random weights, it will generate nonsensical predictions."
      ],
      "metadata": {
        "id": "w0txXSfB1Rhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def try_gpu(i=0):\n",
        "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')"
      ],
      "metadata": {
        "id": "GwJpmF1GFebv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = try_gpu()\n",
        "net = RNNModel(rnn_layer, vocab_size=len(vocab))\n",
        "net = net.to(device)\n",
        "predict('time traveller', 10, net, vocab, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eapyU5gTFOcx",
        "outputId": "c76a43f5-d229-4714-a960-4317cd8c75d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'time travellervv<unk>vvvvvvv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we define a function to *clip the gradients* of a model that is constructed by the high-level APIs. Also, note that we compute the gradient norm over all the model parameters."
      ],
      "metadata": {
        "id": "KUYVRxzg10HO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_clipping(net, theta):\n",
        "    \"\"\"Clip the gradient.\"\"\"\n",
        "    params = [p for p in net.parameters() if p.requires_grad]\n",
        "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
        "    if norm > theta:\n",
        "        for param in params:\n",
        "            param.grad[:] *= theta / norm"
      ],
      "metadata": {
        "id": "7kQbdoDkF78-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before training the model, let us define a function to train the model in one epoch. It differs from how we train the model of *Laboratory 3* in three places:\n",
        "\n",
        "1. Different types of recurrent layers will result in differences in the initialization of hidden states.\n",
        "1. We clip the gradients before updating the model parameters. This ensures that the model does not diverge, even when gradients blow up at some point during the training process.\n",
        "1. We use perplexity to evaluate the model. As discussed in the course, this ensures that sequences of different lengths are comparable.\n",
        "\n",
        "Specifically, when sequential partitioning is used, we initialize the hidden state only at the beginning of each epoch. Since the $i$th subsequence example in the next mini-batch is adjacent to the current $i$th subsequence example, the hidden state at the end of the current mini-batch will be used to initialize the hidden state at the beginning of the next mini-batch. In this way, historical information of the sequence stored in the hidden state might flow over adjacent subsequences within an epoch. However, the computation of the hidden state at any point depends on all the previous mini-batches in the same epoch, which complicates the gradient computation. To reduce computational cost, we detach the gradient before processing any mini-batch, so that the gradient computation of the hidden state is always limited to the time steps in one mini-batch.\n",
        "\n",
        "Same as the `train_epoch()` function in *Laboratory 3*, `optimizer` is a built-in optimization function in PyTorch."
      ],
      "metadata": {
        "id": "E8EUuKWc2KBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(net, train_iter, loss, optimizer, device):\n",
        "    \"\"\"Train a net within one epoch.\"\"\"\n",
        "    state = None\n",
        "    # Sum of training loss, no. of tokens\n",
        "    total_loss = 0\n",
        "    total_tokens = 0\n",
        "    for X, Y in train_iter:\n",
        "        if state is None:\n",
        "            # Initialize `state` when it is the first iteration\n",
        "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
        "        else:\n",
        "            if not isinstance(state, tuple):\n",
        "                # `state` is a tensor for `nn.GRU`\n",
        "                state.detach_()\n",
        "            else:\n",
        "                # `state` is a tuple of tensors for `nn.LSTM`\n",
        "                for s in state:\n",
        "                    s.detach_()\n",
        "        y = Y.T.reshape(-1)\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        y_hat, state = net(X, state)\n",
        "        l = loss(y_hat, y.long()).mean()\n",
        "        optimizer.zero_grad()\n",
        "        l.backward()\n",
        "        grad_clipping(net, 1)\n",
        "        optimizer.step()\n",
        "        total_loss += float(l * y.numel())\n",
        "        total_tokens += y.numel()\n",
        "    return math.exp(total_loss / total_tokens)"
      ],
      "metadata": {
        "id": "EmBMWd6vF4VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training function supports an RNN model implemented using high-level APIs."
      ],
      "metadata": {
        "id": "8X8TY2qj32lD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, train_iter, vocab, lr, num_epochs, device):\n",
        "    \"\"\"Train a model.\"\"\"\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    perplexities = []\n",
        "    # Initialize\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr)\n",
        "    # Train and predict\n",
        "    for epoch in range(num_epochs):\n",
        "        ppl = train_epoch(\n",
        "            net, train_iter, loss, optimizer, device)\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(predict('time traveller', 50, net, vocab, device))\n",
        "            perplexities.append(ppl)\n",
        "    print(f'perplexity {ppl:.1f}, device {str(device)}')\n",
        "    print(predict('time traveller', 50, net, vocab, device))\n",
        "    print(predict('traveller', 50, net, vocab, device))\n",
        "\n",
        "    return perplexities"
      ],
      "metadata": {
        "id": "vr59uClMG-bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can train the RNN model by calling the `train()` function. Since we only use $10000$ tokens in the dataset, the model needs more epochs to converge better."
      ],
      "metadata": {
        "id": "VJQZD20NOdck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs, lr = 500, 1\n",
        "perplexities = train(net, train_iter, vocab, lr, num_epochs, device) #1 min"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6RQ706HFVlc",
        "outputId": "93e85cb4-9aa2-42a8-8127-2db0c80e06e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller and the the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the this the thice some that sime time sion so di\n",
            "time travellere med an ans ano he mant of the thave and have the\n",
            "time travellerthithe monght rousthe tree the the thatour and the\n",
            "time travellerickthe thith sion so deand in the reatlist ou the \n",
            "time traveller surded this timension of his there that in a dint\n",
            "time traveller curee and the enot of camd an aile hathist is tha\n",
            "time traveller pat en sthere wrea touredinst in time tore ard th\n",
            "time travelleris tha fexthestithe wspectofte sime tiok an thes a\n",
            "time travellerit to ge there wral thenting thanethe thile creerp\n",
            "time traveller suthed this soree blate move cong there was avire\n",
            "time traveller the cince arealdiche time traveller the limather \n",
            "time travellerit to ag her aby cand the tome trovelle back the f\n",
            "time travelleris the praven bug ton tis the than s onit te ickte\n",
            "time travelleris tlatwe hty us a gomee in tored andide st thone \n",
            "time traveller s that is yot one angot waitat at wsak as whe hea\n",
            "time travellerit would in wall gat exalliven tand to cante tedth\n",
            "time travellerit wouldife ss the furred snow in taly une have av\n",
            "time traveller scinely d areche warl exper mine along the mithe \n",
            "time travellerit s against reason ta s and bry toukentime pori w\n",
            "time traveller the atmott un thas is sore al and how in por ans \n",
            "time travellerit s against reason said filby bet you warnermilbs\n",
            "time travellerit s against reason sasd fol any of thattirit and \n",
            "time travellerit o lars ho knot or call one s mannes time than l\n",
            "time traveller thr a done there was al mounaid annat whisediman \n",
            "time traveller hald iner abmelthene of the gereot surelouth stir\n",
            "time traveller came back and for d as on mald any hirguithest th\n",
            "time traveller friceeded heve inger at wass the tyon sammot mean\n",
            "time traveller arter thot hestan e of upe bove frow of storis le\n",
            "time traveller hal sanding than that no alconly on mone ably tim\n",
            "time travellerit s against reason said fily of courdean the thir\n",
            "time traveller proceeded the provitabyoc thackness cin fored rea\n",
            "time traveller cuthe wsye and the time traveller cute is ale hav\n",
            "time traveller smiled if on he pack to beendeno so a cime ta oor\n",
            "time traveller firectinnt tt rover tas er ans spaceenol treco hi\n",
            "time traveller after the pauserequired for thecpres have done so\n",
            "time traveller proceeded an move spait and there was thatluxurio\n",
            "time traveller hamd bnca fore wilnshis one thing diencrof pastio\n",
            "time travellerit on phe dtagnever he herenth af beas the faul th\n",
            "time traveller hald aner for shakend indst ond why candotsed ino\n",
            "time traveller proceeded hry tal gork tower suthentine or hre fo\n",
            "time traveller held in his hand was a glitteringmetallic framewo\n",
            "time traveller but now anouthe mode masterations of space but yo\n",
            "time traveller held in his hand was f anithat y anof thing is th\n",
            "time traveller came that is all right said the psychologist thou\n",
            "time traveller hole about in time for instance if a d haure the \n",
            "time travelleryou can maving fourthid and in tinet it tas o jurk\n",
            "time traveller but now you begin to seethe object of my investig\n",
            "perplexity 1.3, device cpu\n",
            "time traveller but now you begin to seethe object of my investig\n",
            "traveller but now you begin to seethe object of my investig\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we plot the perplexities obtained during training, using the `plot_perplexity()` function."
      ],
      "metadata": {
        "id": "u4B8zHv6PMbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_perplexity(perplexities):\n",
        "    epochs = range(10, len(perplexities * 10) + 1, 10)\n",
        "    plt.plot(epochs, perplexities, 'b', label='Train perplexity')\n",
        "    plt.title('Training perplexity')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Perplexity')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YvS_979fHXRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_perplexity(perplexities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WeOdstSoIfgG",
        "outputId": "7f347484-83af-4bd9-9230-537f79fc7e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gated recurrent units (GRU)"
      ],
      "metadata": {
        "id": "8ObmDpUTTwCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using PyTorch's high-level APIs, we can directly replace the `nn.RNN` with the `nn.GRU` layer in order to use a gated recurrent unit (GRU). The rest of the code is exactly the same."
      ],
      "metadata": {
        "id": "l34_ygLtP479"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size, num_hiddens, device = len(vocab), 256, try_gpu()\n",
        "num_epochs, lr = 500, 1\n",
        "\n",
        "num_inputs = vocab_size\n",
        "gru_layer = nn.GRU(num_inputs, num_hiddens)\n",
        "model = RNNModel(gru_layer, len(vocab))\n",
        "model = model.to(device)\n",
        "perplexities = train(model, train_iter, vocab, lr, num_epochs, device) #4 min"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW6NK446Tyzk",
        "outputId": "aaae3d2a-0572-4c3f-b2dc-7a91ef625353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time traveller te te te te te te te te te te te te te te te te t\n",
            "time travellere the the the the the the the the the the the the \n",
            "time travellere the the the the the the the the the the the the \n",
            "time travellere the the the the the the the the the the the the \n",
            "time traveller and the the the the the the the the the the the t\n",
            "time traveller and the the the the the the the the the the the t\n",
            "time travellerereat and and and and and and and and and and and \n",
            "time travellereation the there the there the there the there the\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller and the the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller thee thing sime thaveller simentions of space ald\n",
            "time traveller the time traveller the time traveller the time tr\n",
            "time traveller that is that a somurat of the inthe red have all \n",
            "time traveller theng the time traveller thereass that is the thi\n",
            "time traveller three dimensions of space we than a smallextertio\n",
            "time travellerichedrict all the three than thepe thing the time \n",
            "time travellericherent and his foutard thing this in and on has \n",
            "time travellericher convin i becare yor gnat fourd you instance \n",
            "time travellerit s against reason said filby an antles this fitt\n",
            "time traveller for so it will be cannot move about in time for i\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time travellerit w al auntly but you are wo ng said the psycholo\n",
            "time traveller reford ind and they tould me trave lere afcarlong\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller came back and in and we hear dime simely twono he\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller atternithe modient only twund theel time travelle\n",
            "time traveller atternithe morear extrave ilbr a cabd canveridet \n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller comend drave i sai ab an and whath a slige to esp\n",
            "time travellerit s against reason said filby bat koushime spame \n",
            "time traveller after the pauserequired for the proper assimilati\n",
            "time traveller uf an thes atanss he time traveller for so it wil\n",
            "time traveller wht so diched the prover as wisher and sut it in \n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller with a slight accession ofcheerfulness really thi\n",
            "time traveller with a slight accession ofcheerfulness really thi\n",
            "time traveller smiled roukkno to acceptidit for this thatfollows\n",
            "time traveller with a slight accession ofcheerfulness really thi\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller with a slight accession ofcheerfulness really thi\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "perplexity 1.0, device cpu\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "traveller with a slight accession ofcheerfulness really thi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can similarly plot the perplexity during training."
      ],
      "metadata": {
        "id": "VJu6dEQAQpiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_perplexity(perplexities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "erDt9sqFUVBe",
        "outputId": "725a1315-ebc5-41cf-cc72-7286e6fee268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgU5dX38e9hHWBYFAZEQQcUUUQYdFBAiWAUUTbjEjViXIPb4/a4m2jQqDGuedREMUExrxtuqNFowF1CFAdF1IABFCOKMmBEAQGB8/5xV8MwDEwzTHdNd/0+11VXV1VXV53C8fTdd92LuTsiIpIc9eIOQEREskuJX0QkYZT4RUQSRolfRCRhlPhFRBJGiV9EJGGU+CVnmNnzZnZibR9bl5nZODO7thbOs9TMOtdGTJL7GsQdgOQ3M1taYbMpsBJYE22f7u4Ppnsudz80E8cmgbsXptbNbBww391/FV9EEiclfsmoSglnHnCau79Y+Tgza+Duq7MZW9ySeM9SN6iqR2JhZgPMbL6ZXWpmXwL3mdk2ZvasmZWb2X+j9Q4VPvOqmZ0WrZ9kZpPN7Obo2E/M7NAaHtvJzF43s+/M7EUz+4OZPVBN3FeY2SIzm2dmx1d4v3F0nf+Y2VdmdreZNdnMPW/2fFVcf6iZTTezb8xsipn1iPYfE91Xi2j7UDP70syKom03s13MbBRwPHBJVP3zVzO72MyeqHSd283s/9L97ym5RYlf4rQdsC2wEzCK8Pd4X7S9I/A9cOdmPr8v8BHQBrgRGGtmVoNjHwKmAq2B0cAJacTdBtgBOBG4x8y6Ru/dAOwKlAC7RMdctZl7ru5865hZL+Be4PQo1jHAM2bW2N3HA1OA282sNTCW8OuqvOI53P0e4EHgRncvdPdhwAPAYDNrFV2nAXAs8Jdq/h0kRynxS5zWAr9295Xu/r27L3b3J9x9ubt/B1wHHLCZz3/q7n9y9zXA/UB7oN2WHGtmOwK9gavcfZW7TwaeSSP2K6O4XwOeA34afZGMAi5w96+je7iekESrvOfNna+Ka44Cxrj7W+6+xt3vJzwz6RO9fzZwIPAq8Fd3fzaN+8DdFwCvA0dHuwYDi9x9Wjqfl9yjxC9xKnf3FakNM2tqZmPM7FMz+5aQjFqZWf1NfP7L1Iq7L49WC7fw2O2BryvsA/ismrj/6+7LKmx/Gp2niPAAe1pUFfMN8EK0P2WDe67mfJXtBFyYOnd0/o6pY939G+AxoDtwSzX3UNn9wMhofSTw/7bw85JDlPglTpWHhr0Q6Ars6+4tgB9F+zdVfVMbFgDbmlnTCvs6VvOZbcysWYXtHYEvgEWE6qk93L1VtLSs+ICbje95c+er7DPgugrnbuXuTd39YQAzKwFOAR4Gbt9M/FXF8BTQw8y6A0MJ1UGSp5T4pS5pTkic35jZtsCvM31Bd/8UKANGm1kjM+sLDEvjo1dHx/cnJMrH3H0t8CfgNjNrC2BmO5jZITU5XxXH/Ak4w8z2taCZmQ0xs+ZmVkCoq78COBnYwczO2sS1vgI2aNMf/Qp5nOh5h7v/J42YJUcp8Utd8nugCaHk/CahmiQbjgf6AouBa4HxhLrzTfkS+C+hVP4gcIa7z4reuxSYA7wZVVe9SPgVszmbO9867l4G/ILwwPu/0XVOit7+LfCZu9/l7isJ1TXXmlmXKq43FugWVRc9VWH//cCeqJon75kmYhHZkJmNB2a5+0a/OMxsAPCAu3fY6IM1u1atnm8rY9kRmAVs5+7fxh2PZI5K/JJ4ZtbbzHY2s3pmNhgYQajzTgwzqwf8L/CIkn7+U89dkdCO/klC2/j5wJnu/m68IWVP9GD5K0JrosExhyNZoKoeEZGEUVWPiEjC5ERVT5s2bby4uDjuMEREcsq0adMWuXtR5f05kfiLi4spKyuLOwwRkZxiZp9WtV9VPSIiCaPELyKSMEr8IiIJk7E6fjO7lzDmyEJ3715h/zmE4WPXAM+5+yWZikFE0vPDDz8wf/58VqyoPHCo5IKCggI6dOhAw4YN0zo+kw93xxHGFFk3mYOZDST0iuzp7itTA1mJSLzmz59P8+bNKS4uZtNz2Uhd5O4sXryY+fPn06lTp7Q+k7GqHnd/Hfi60u4zgRuiQaRw94WZur6IpG/FihW0bt1aST8HmRmtW7feol9r2a7j3xXob2ZvmdlrZtY7y9cXkU1Q0s9dW/rfLtuJvwFhvtE+wMXAo5uaI9XMRplZmZmVlZeXV3VItZ57Dm64ocaxiojkpWwn/vnAkx5MJcw/2qaqA939HncvdffSoqKNOp6l5cUX4Te/AQ1HJFJ3LV68mJKSEkpKSthuu+3YYYcd1m2vWrVqs58tKyvj3HPPzVKkmzdv3jy6d+9e/YFVeOaZZ7ghKqU+9dRT/Otf/6rN0DaS7Z67TwEDgVfMbFegEWHSjYzo3BmWL4eFC6HdpqbgFpFYtW7dmunTpwMwevRoCgsLueiii9a9v3r1aho0qDpVlZaWUlpampU4q4tlawwfPpzhw4cDIfEPHTqUbt261fp1UjJW4jezh4F/Al3NbL6ZnQrcC3Q2sw+AR4ATPYPDg+68c3idOzdTVxCRTDjppJM444wz2HfffbnkkkuYOnUqffv2pVevXvTr14+PPvoIgFdffZWhQ4cC4UvjlFNOYcCAAXTu3Jnbb6962uHCwkIuuOAC9thjD3784x+TqkqeO3cugwcPZu+996Z///7MmjWrylhGjx7NCSecQN++fenSpQt/+tOfNrrGmjVruPjii+nduzc9evRgzJgxANx2222ccsopALz//vt0796d5cuXM27cOP7nf/6HKVOm8Mwzz3DxxRdTUlLC3Llz2Wuvvdadd/bs2Rts11TGSvzuftwm3hqZqWtW1jmaVfTjj6Ffv2xdVSS3nX8+RAXwWlNSAr///ZZ9Zv78+UyZMoX69evz7bff8sYbb9CgQQNefPFFrrjiCp544omNPjNr1ixeeeUVvvvuO7p27cqZZ565Udv2ZcuWUVpaym233cY111zD1VdfzZ133smoUaO4++676dKlC2+99RZnnXUWL7/88kaxjB49mhkzZvDmm2+ybNkyevXqxZAhQza4xtixY2nZsiVvv/02K1euZL/99mPQoEGcd955DBgwgAkTJnDdddcxZswYmjZtuu5z/fr1Y/jw4QwdOpSjjjoKgJYtWzJ9+nRKSkq47777OPnkk7fsH7IKOTFIW02lBvT8+ONYwxCRGjj66KOpX78+AEuWLOHEE09k9uzZmBk//PBDlZ8ZMmQIjRs3pnHjxrRt25avvvqKDh02nNWyXr16HHPMMQCMHDmSI444gqVLlzJlyhSOPvrodcetXLl+2uWKsQCMGDGCJk2a0KRJEwYOHMjUqVMpKSlZ9/7EiROZMWMGjz/++Lr4Z8+eTadOnRg3bhw9evTg9NNPZ7/99qv23+G0007jvvvu49Zbb2X8+PFMnTq12s9UJ68Tf0EB7LCDEr/IltjSknmmNGvWbN36lVdeycCBA5kwYQLz5s1jwIABVX6mcePG69br16/P6tWrq72OmbF27VpatWq17lnD5mJJfWZz2+7OHXfcwSGHHLLRuWbPnk1hYSFffPFFtbEBHHnkkVx99dUceOCB7L333rRu3Tqtz21O3o/Vs/POSvwiuW7JkiXssMMOAIwbN26rzrV27dp1JfGHHnqI/fffnxYtWtCpUycee+wxICTu9957b5PnePrpp1mxYgWLFy/m1VdfpXfvDbskHXLIIdx1113rfpn8+9//ZtmyZSxZsoRzzz2X119/ncWLF6+Lo6LmzZvz3XffrdsuKCjgkEMO4cwzz6yVah5IQOLv3FkPd0Vy3SWXXMLll19Or1690irFb06zZs2YOnUq3bt35+WXX+aqq64C4MEHH2Ts2LH07NmTPfbYg6effnqT5+jRowcDBw6kT58+XHnllWy//fYbvH/aaafRrVs39tprL7p3787pp5/O6tWrueCCCzj77LPZddddGTt2LJdddhkLF244gMGxxx7LTTfdRK9evZgbJa/jjz+eevXqMWjQoK2695ScmHO3tLTUazoRy29+A1ddFZp1NmlSy4GJ5ImZM2ey++67xx1GVhQWFrJ06dIaf76qJqeZdvPNN7NkyRJ+85vfbPKYqv4bmtk0d9+ovWte1/HD+pY98+ZBQv6uRSSP/OQnP2Hu3LnrWhjVhrxP/Km2/B9/rMQvImxVaR9CiT+bJkyYUOvnTEQdP+gBr0h1cqHaV6q2pf/t8j7xFxVBs2Z6wCuyOQUFBSxevFjJPwelxuMvKChI+zN5X9VjFkr9KvGLbFqHDh2YP38+NR0JV+KVmoErXXmf+CEk/jlz4o5CpO5q2LBh2rM3Se7L+6oeWN+JS79iRUQSkvg7d4bvv4evvoo7EhGR+CUm8YMe8IqIQMISvx7wiogkJPEXF4fWPUr8IiIJSfyNG0OHDkr8IiKQkMQPassvIpKSyTl37zWzhdH8upXfu9DM3MzaZOr6lWl4ZhGRIJMl/nHA4Mo7zawjMAj4TwavvZHOnWHBgjA8s4hIkmUs8bv768DXVbx1G3AJkNXuVKlROufNy+ZVRUTqnqzW8ZvZCOBzd9/0nGbrjx1lZmVmVlYb44eoSaeISJC1xG9mTYErgKvSOd7d73H3UncvLSoq2urrK/GLiATZLPHvDHQC3jOzeUAH4B0z2y4bF2/TBgoL9YBXRCRro3O6+/tA29R2lPxL3X1RNq5vtn6wNhGRJMtkc86HgX8CXc1svpmdmqlrpUtt+UVEMljid/fjqnm/OFPX3pTOneH558PwzGbZvrqISN2QmJ67EBL/ihWhPb+ISFIlLvGDqntEJNkSlfhTnbiU+EUkyRKV+HfaScMzi4gkKvE3agQdOyrxi0iyJSrxg0bpFBFJXOJXJy4RSbrEJf7OneHLLzU8s4gkVyITP8Ann8Qbh4hIXBKb+FXdIyJJldjErwe8IpJUiUv8rVtDixYq8YtIciUu8ZtplE4RSbbEJX5Q4heRZEts4v/kE1i7Nu5IRESyL5GJf+edw/DMn30WdyQiItmXyMS///7hdeLEeOMQEYlDIhP/HnuEkTr/+te4IxERyb5Mzrl7r5ktNLMPKuy7ycxmmdkMM5tgZq0ydf3NxwbDhsGLL8L338cRgYhIfDJZ4h8HDK60bxLQ3d17AP8GLs/g9Tdr2LCQ9F96Ka4IRETikbHE7+6vA19X2jfR3VdHm28CHTJ1/eoccAAUFsKzz8YVgYhIPOKs4z8FeH5Tb5rZKDMrM7Oy8vLyWr9448YwaFBI/O61fnoRkTorlsRvZr8EVgMPbuoYd7/H3UvdvbSoqCgjcQwbBp9/Du++m5HTi4jUSVlP/GZ2EjAUON493rL2YYeFB71q3SMiSZLVxG9mg4FLgOHuHvtUKG3bQp8+SvwikiyZbM75MPBPoKuZzTezU4E7gebAJDObbmZ3Z+r66Ro2DKZNgy++iDsSEZHsyGSrnuPcvb27N3T3Du4+1t13cfeO7l4SLWdk6vrpGjo0vD73XLxxiIhkSyJ77lbUvbt68YpIsiQ+8asXr4gkTeITP6gXr4gkixI/6sUrIsmixI968YpIsijxR9SLV0SSQok/ol68IpIUSvyRtm1h332V+EUk/ynxV6BevCKSBEr8FRx+eHi988544xARySQl/gq6dYOf/xxuvhk+/DDuaEREMkOJv5Kbb4bmzeGMM2Dt2rijERGpfUr8lRQVheQ/eTLce2/c0YiI1D4l/iqcdBL86EdwySWwcGHc0YiI1C4l/iqYwZgxsHQpXHhh3NGIiNQuJf5N2G03uOwyeOCBMHKniEi+UOLfjCuugF12gTPPhBUr4o5GRKR2ZHLqxXvNbKGZfVBh37ZmNsnMZkev22Tq+rWhoADuvhvmzIHrr487GhGR2pHJEv84YHClfZcBL7l7F+ClaLtO+/GPYeRIuOEGmDkz7mhERLZeWonfzFpv6Ynd/XXg60q7RwD3R+v3A4dv6XnjcMstoW3/yJGwcmXc0YiIbJ10S/xvmtljZnaYmdlWXK+duy+I1r8E2m3qQDMbZWZlZlZWXl6+FZfcem3bwn33wTvvwEUXxRqKiMhWSzfx7wrcA5wAzDaz681s1625sLs7sMlpT9z9HncvdffSoqKirblUrRg+HC64IIzj88QTcUcjIlJzaSV+Dya5+3HAL4ATgalm9pqZ9d2C631lZu0Botec6h51ww2wzz5wyinw8cdxRyMiUjNp1/Gb2XlmVgZcBJwDtAEuBB7agus9Q/jSIHp9egs+G7tGjWD8eKhXD445RvX9IpKb0q3q+SfQAjjc3Ye4+5Puvtrdy4C7q/qAmT0cfa6rmc03s1OBG4CDzWw2cFC0nVOKi0N9f1lZGNJBRCTXmKcxu7iZ/dTdH62072h3fyxjkVVQWlrqZWVl2bhU2i64AH7/e3jySfjJT+KORkRkY2Y2zd1LK+9Pt8RfVXv7y7cupNz2u99B795w8snwySdxRyMikr4Gm3vTzA4FDgN2MLPbK7zVAlidycDqulR9f69eocXPpEmw3XZxRyUiUr3qSvxfAGXACmBaheUZ4JDMhlb3deoUqno+/jgM4/yf/8QdkYhI9dKt42/g7rGV8OtiHX9FU6bAYYdBixZhJM9dt6qHg4hI7ahRHb+ZpR7ovmtmMyovGYk0B/XrB6++Gkbw7N8fZuhfRkTqsM3W8QPnRa9DMx1Irispgddfh4MPhgMOgBdegH33jTsqEZGNbbbEX2FcnWbu/mnFBeiU+fByy267wRtvQOvWYVTPSZPijkhEZGPpNud81MwutaCJmd0B/DaTgeWq4uKQ/IuLYdCgUN9/4YWhKmh1ottBiUhdkW7i3xfoCEwB3ia09tkvU0Hluvbt4R//CAO6de4cXgcOhKIi+NnP4PHHIY1n6iIiGZFu4v8B+B5oAhQAn7j72oxFlQdatoSzzw51/YsWhRE9Dz88tPo5+ugw3IOSv4jEId3E/zYh8fcG+gPHmVlWhmvIB82bwxFHhDF+FiyAs86Cm2+G666LOzIRSaLqWvWknBoNyAawABhhZidkKKa8Vr8+3HEHfPstXHll+GVwzjlxRyUiSZJu4p9mZiOBzu5+jZntCHyUwbjyWr16ofT/3Xdw7rmh49eJJ1b/ORGR2pBuVc8fgb7AcdH2d8AfMhJRQjRoAI88Epp9nnJKGPpBRCQb0m7V4+5nE8bswd3/CzTKWFQJUVAATz0VOnodeyxMnBh3RCKSBGm36jGz+kRz5JpZEaBWPbWgsBCeew66dQutfp5/Pu6IRCTfpZv4bwcmAG3N7DpgMnB9xqJKmG22gb//Hbp0gSFD4Fe/UmcvEcmctB7uuvuDZjYN+DFghCkYZ2Y0soRp1w7++c/Qwue660IHsIceCp3BRERqU3Wjc26bWoCFwMOEydW/ivbViJldYGYfmtkHZvawmRXU9Fz5pGlTGDs2tPh5660wycsrr8QdlYjkm+qqeqYRJmKZVsVSowHyzWwH4Fyg1N27A/WBY2tyrnx10kkwdSq0agUHHQTXXgtr9URFRGrJZqt63D1TI3A2AJqY2Q9AU8LYP1JB9+5QVgannx46ev3lL2Goh6OOCkNAm8UdoYjkqnQf7mJmR5jZrWZ2i5kdXtMLuvvnwM3Afwi9gJe4+0YNGc1slJmVmVlZeXl5TS+X0woL4YEH4OGHw2ifv/sd7LUX7LILXHpp+GLQeD8isqXSSvxm9kfgDOB94APgDDOrUQcuM9sGGEEYz397oFnUK3gD7n6Pu5e6e2lRUVFNLpUXzNa38f/yS/jzn0Prn1tvhd69wzJvXtxRikguSbfEfyBwiLvf5+73AYdF+2riIMLonuXu/gPwJNCvhudKlDZt4NRTw4ifX30FY8bAnDmw995h1E8RkXSkm/jnADtW2O4Y7auJ/wB9zKypmRmhiaiahm6hbbeFUaNCdU/79nDIIWHET1X9iEh10k38zYGZZvaqmb0C/AtoYWbPmNkzW3JBd38LeBx4h1B1VA+4Z0vOIevtsgu8+WYY9vnii+G442DZsrijEpG6zDyNIqKZHbC59939tVqLqAqlpaVeVlaj1qOJ4Q433QSXXw577AETJsDOO8cdlYjEycymuXtp5f3V9tyNxugZ7e4DMxKZ1AqzMKtXSUl4GLzPPmGe3z33jDsyEalrqq3qcfc1wFoza5mFeGQrDRoEb78NTZqE9Tk1fRIjInkr3YlYlgLvm9kkYF0Nsrufm5GoZKvsvDNMmgT9+4eev5MnQ4cOcUclInVFuon/yWiRHLH77mHEz4ED4eCD4fXXIcHdIUSkgnRH57zfzJoAO7q7plzMEXvvDc8+G5p6Dh4ML78c5vgVkWRLt+fuMGA68EK0XbKlzTglHj/6ETzxBMyYAcOGwfLlcUckInFLtx3/aGAf4BsAd58OdM5QTFLLDjssjPkzeXIY6O377+OOSETilPbUi+6+pNI+DRScQ445Jgzx8Le/hXH+p06NOyIRiUu6if9DM/sZUN/MupjZHcCUDMYlGfCLX4TWPsuXQ79+YbjnVavijkpEsi3dxH8OsAewkjAD1xLg/EwFJZlz0EHw/vtwwglhgpd99gn1/yKSHNVNvVhgZucDNxIGV+vr7r3d/VfuviIrEUqta9kyTO/49NOwYAGUlsJvf6sJ3kWSoroS//1AKWEwtUMJE6hInhg+HD78EEaMgCuugAEDNLa/SBJUl/i7uftIdx8DHAX8KAsxSRa1aQOPPhpa/bz/PvTsCQ89FHdUIpJJ1SX+H1Ir7q6KgDxlBscfD9Onh7l+jz8eRo6EJZXbcYlIXqgu8fc0s2+j5TugR2rdzL7NRoCSPZ06wWuvwTXXwCOPhJE+//GPuKMSkdq22cTv7vXdvUW0NHf3BhXWW2QrSMmeBg1CM8/Jk6FevdDz97rrNLOXSD5JtzmnJEyfPvDuu2Fs/1/9Cn72M/X4FckXSvyySS1ahIe+v/sdjB8fSv9ffBF3VCKytWJJ/GbWysweN7NZZjbTzPrGEYdULzWz11NPwaxZ0Lt3mOBdRHJXXCX+/wNecPfdgJ7AzJjikDQNHw5TpkCjRmGCl/Hj445IRGoq64k/msLxR8BYAHdf5e7fZDsO2XJ77hkGdystDXX/v/ylevuK5KI4SvydgHLgPjN718z+bGbNKh9kZqPMrMzMysrLy7MfpVSpqAhefBFOPRWuvz6U/ufOjTsqEdkScST+BsBewF3u3oswh+9llQ9y93vcvdTdS4s0Z2Cd0rgx/PnP8PDDod6/Z0+49141+RTJFXEk/vnAfHd/K9p+nPBFIDnm2GPDyJ777BN+ARx5JCxaFHdUIlKdrCd+d/8S+MzMuka7fgz8K9txSO3o2DFU/dx0U5jfd889wyTvIlJ3xdWq5xzgQTObAZQA18cUh9SCevXgoovg7bdh223h0EPhGc3ILFJnNYjjotGcvaVxXFsyp2fPkPwHDAg9fSdPDuP9iEjdop67UquaNg0TvGy7LQwdqp6+InWREr/Uuvbt4a9/hW++CZO8LF8ed0QiUpESv2REz56huee0afDzn8PatXFHJCIpSvySMcOGwS23wBNPhBE+RaRuiOXhriTH+efDRx+Fydx33RVOOinuiEREiV8yygzuuCMM6zBqFLRrF5p7ikh8VNUjGdewITz2WJjPd8QImDAh7ohEkk2JX7KiVSt4+WXYe284+mh46KG4IxJJLiV+yZpWrWDixDCi58iRMHZs3BGJJJMSv2RV8+bw3HMwaBCcdlqo/xeR7FLil6xL9e4dMQLOPTfM6Ssi2aPEL7Fo3Dg88D32WLjsMrj0UnXyEskWNeeU2DRsCA88AC1bwo03wiefwP33Q5MmcUcmkt+U+CVW9evDXXfBLrvAxRfDZ5+FaqC2beOOTCR/qapHYmcWxvN//HGYPh369IGZM+OOSiR/KfFLnXHkkfDaa7BsGfTrB6+8EndEIvlJiV/qlH32gbfegu23D00+H3ww7ohE8k9sid/M6pvZu2b2bFwxSN1UXAz/+Efo6HXiiaHdv4jUnjhL/OcBqsmVKrVqFebtLSmBn/4Upk6NOyKR/BFL4jezDsAQ4M9xXF9yQ2FhKO23awdDhsCcOXFHJJIf4irx/x64BNhklx0zG2VmZWZWVl5enr3IpE5p1w5eeAHcYfBgWLgw7ohEcl/WE7+ZDQUWuvu0zR3n7ve4e6m7lxYVFWUpOqmLdt0Vnn02TNw+ZAgsXRp3RCK5LY4S/37AcDObBzwCHGhmD8QQh+SQPn1g/Hh4551Q5//DD3FHJJK7sp743f1yd+/g7sXAscDL7j4y23FI7hk2LPTyff55OOOMUP0jIltOQzZIThk1Cj7/HK65Btq3h2uvjTsikdwTa+J391eBV+OMQXLP6NGwYAFcd114+HvOOXFHJJJbVOKXnGMGf/wjlJfDeedBUVEY3llE0qMhGyQnNWgADz8cevf+/Ofw4otxRySSO5T4JWcVFIQhnHfbDX7yEygrizsikdygxC85rVWr0MGrdWs47DCYPTvuiETqPiV+yXnbbw8TJ4bmnYMGwUcfxR2RSN2mxC95Yddd4W9/C71699knDPAmIlVT4pe80bs3TJsGXbrAiBHw619rAneRqijxS17ZcUd44w046aTQyWv4cPjmm7ijEqlblPgl7zRpAvfeG9r6T5wYfgl8+GHcUYnUHUr8kpfM4Mwzw7y9S5fCvvvC66/HHZVI3aDEL3ltv/1CvX+HDnD00WGcH5GkU+KXvLf99vDkk7BsWRjSedWquCMSiZcSvyRCt26h3n/KFLj44rijEYmXEr8kxk9/CuefD7ffHsb5EUkqJX5JlBtvhP33h9NOU0sfSS4lfkmUhg3h0UehRQs44gj49tu4IxLJPiV+SZz27UPynzsXTj5ZUzhK8ijxSyL17x+qfZ58Es46C777Lu6IRLIn64nfzDqa2Stm9i8z+9DMzst2DCIAF1wA//u/MGZMaPXz1FNxRySSHXGU+FcDF7p7N6APcLaZdYshDkk4M7jlltDEc9ttw2Quhx8On30Wd2QimZX1xO/uC9z9nWj9O2AmsEO24xBJ6dMnzN51440waRLsvpP8vZoAAAo2SURBVDvcdhusXh13ZCKZEWsdv5kVA72At6p4b5SZlZlZWXl5ebZDk4Rp2DB07PrwQzjggFAF1Lt3+DUgkm9iS/xmVgg8AZzv7hs1qnP3e9y91N1Li4qKsh+gJFJxMTz7LDz2GCxaFMb6OflkWLgw7shEak8sid/MGhKS/oPu/mQcMYhsihkcdRTMnAmXXgoPPBBm+LrzTlX/SH6Io1WPAWOBme5+a7avL5KuwkK44QaYMQNKS+Gcc1T9I/khjhL/fsAJwIFmNj1aDoshDpG07L57eOj76KNQXh6qf44/Xq1/JHfF0apnsrubu/dw95Jo+Vu24xDZEmZhPP9Zs+CXv4QnnoCuXWH0aFi+PO7oRLaMeu6KbIHCQrj22vAFMGwYXH11+AJ46CEN/SC5Q4lfpAaKi2H8+DCdY9u2oeqnb18YN06Tu0vdp8QvshX694e33w6TvCxcGJp+tmsXegA/8kiY9SsOa9aE6x98cJiD4JNP4olD6ibzHPh9Wlpa6mVlZXGHIbJZ7uFL4JFHwq+BL76Apk1hyBDYcUdo0CB0FGvQYP3SoQP07Am77Ra2t9bKlfCXv4ReyHPmwE47hXmG164Nw1BfeGHoqSzJYGbT3L10o/1K/CK1b+1amDw5fAk8/XSo/lm9Oixr1258fOPG0L07lJSEpUsXaNUqLC1bhteCgk1fb+nSMNjcrbeGL5zSUrj88vDLY8GC0Afh7rtDHH37hi+A4cPDF1FtW7YsNIF9/33YZptwPzvvDPVUv5B1SvwidcTataEqZtWqUAUzfXpY3nsP3n0XFi+u+nONGkHz5qGFUcUFwrDSy5fDwIEh4R900Pr3UpYuDc8gbrsNPv44JOL27cOvjo4dw2uHDuGZRZMmYSkoWP/aqNH6L68ffli/vnw5fPBBiH36dPj3vzd+0N2sGfToEX7dlJSE665du35Zsya8rl4NK1aEXy4VX9esgdatQzVaxaVNm3D+FSs2Xtyhfv1wn/Xrr18aNQrxNG0atvOZEr9IDnAPVTOffgpLloQS+jffrF9fujQck/rfNrXeqFF4wJxONc6aNfDcc2FguvnzQ3+E1OvWPJPYaSfo1Ssk9l69QqL/+uvwhVbxy23Jki07r1lI3mvW1Dy2TSkoCF8ChYXh33DVqrCsXLl+fdWq9XGkvkxT66nqu1QVXmodQryrV4fX1DqEL5uK1X2pL6Sqzm8Wfsn171+z+9tU4q+FWkURqS1m60vemVK/fqjmGT58w/3uISmXl68vNX///frXVas2fk7RsGGopuraNVTrVFZcDHvtteE1Pv00/KpJlcZTJfLUa0FBWBo3Dq+pZx9LlsBXX224LFq04WcqftZs/a+J1LJ2bUjqy5aFL9Fly9YvK1eG5N+4cVhS66lEXvnL1n39r5/UL6DUOmyY1FPrsOEXQupX05o1VZ8fwq+82qbELyJASJSp5wqZvEZxcVi2VCq2rl1rO6rk0eMWEZGEUeIXEUkYJX4RkYRR4hcRSRglfhGRhFHiFxFJGCV+EZGEUeIXEUmYnBiywczKgU+rOawNsCgL4dQ1uu9k0X0nz9bc+07uXlR5Z04k/nSYWVlVY1LkO913sui+kycT966qHhGRhFHiFxFJmHxK/PfEHUBMdN/JovtOnlq/97yp4xcRkfTkU4lfRETSoMQvIpIwOZ/4zWywmX1kZnPM7LK446ltZnavmS00sw8q7NvWzCaZ2ezodZtov5nZ7dG/xQwz22vTZ667zKyjmb1iZv8ysw/N7Lxof17fN4CZFZjZVDN7L7r3q6P9nczsregex5tZo2h/42h7TvR+cZzxbw0zq29m75rZs9F23t8zgJnNM7P3zWy6mZVF+zL6t57Tid/M6gN/AA4FugHHmVm3eKOqdeOAwZX2XQa85O5dgJeibQj/Dl2iZRRwV5ZirG2rgQvdvRvQBzg7+u+a7/cNsBI40N17AiXAYDPrA/wOuM3ddwH+C5waHX8q8N9o/23RcbnqPGBmhe0k3HPKQHcvqdBeP7N/6+6eswvQF/h7he3LgcvjjisD91kMfFBh+yOgfbTeHvgoWh8DHFfVcbm8AE8DByfwvpsC7wD7EnpuNoj2r/u7B/4O9I3WG0THWdyx1+BeO0QJ7kDgWcDy/Z4r3Ps8oE2lfRn9W8/pEj+wA/BZhe350b58187dF0TrXwLtovW8+/eIfsb3At4iIfcdVXlMBxYCk4C5wDfuvjo6pOL9rbv36P0lQOvsRlwrfg9cAqyNtluT//ec4sBEM5tmZqOifRn9W9dk6znO3d3M8rJNrpkVAk8A57v7t2a27r18vm93XwOUmFkrYAKwW8whZZSZDQUWuvs0MxsQdzwx2N/dPzeztsAkM5tV8c1M/K3neon/c6Bjhe0O0b5895WZtQeIXhdG+/Pm38PMGhKS/oPu/mS0O+/vuyJ3/wZ4hVDN0crMUgW1ive37t6j91sCi7Mc6tbaDxhuZvOARwjVPf9Hft/zOu7+efS6kPBFvw8Z/lvP9cT/NtAlevrfCDgWeCbmmLLhGeDEaP1EQh14av/Poyf/fYAlFX4u5gwLRfuxwEx3v7XCW3l93wBmVhSV9DGzJoRnGzMJXwBHRYdVvvfUv8lRwMseVf7mCne/3N07uHsx4f/hl939ePL4nlPMrJmZNU+tA4OAD8j033rcDzZq4cHIYcC/CfWgv4w7ngzc38PAAuAHQn3eqYT6zJeA2cCLwLbRsUZo5TQXeB8ojTv+Gt7z/oR6zxnA9Gg5LN/vO7qXHsC70b1/AFwV7e8MTAXmAI8BjaP9BdH2nOj9znHfw1be/wDg2aTcc3SP70XLh6kclum/dQ3ZICKSMLle1SMiIltIiV9EJGGU+EVEEkaJX0QkYZT4RUQSRolfEs3M1kSjIqaWWhvh1cyKrcKoqiJ1hYZskKT73t1L4g5CJJtU4hepQjRG+o3ROOlTzWyXaH+xmb0cjYX+kpntGO1vZ2YTonH03zOzftGp6pvZn6Kx9SdGvXExs3MtzDcww8weiek2JaGU+CXpmlSq6jmmwntL3H1P4E7C6JEAdwD3u3sP4EHg9mj/7cBrHsbR34vQCxPCuOl/cPc9gG+AI6P9lwG9ovOckambE6mKeu5KopnZUncvrGL/PMKEKB9HA8Z96e6tzWwRYfzzH6L9C9y9jZmVAx3cfWWFcxQDkzxMpoGZXQo0dPdrzewFYCnwFPCUuy/N8K2KrKMSv8im+SbWt8TKCutrWP9cbQhhzJW9gLcrjEIpknFK/CKbdkyF139G61MII0gCHA+8Ea2/BJwJ6yZSabmpk5pZPaCju78CXEoYVnijXx0imaJShiRdk2i2q5QX3D3VpHMbM5tBKLUfF+07B7jPzC4GyoGTo/3nAfeY2amEkv2ZhFFVq1IfeCD6cjDgdg9j74tkher4RaoQ1fGXuvuiuGMRqW2q6hERSRiV+EVEEkYlfhGRhFHiFxFJGCV+EZGEUeIXEUkYJX4RkYT5/5vceSyYxc84AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Long short-term memory (LSTM)"
      ],
      "metadata": {
        "id": "o6VEFsqGUbhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exactly the same as for the GRU, we replace `nn.RNN` with `nn.LSTM` in order to use a long short-term memory (LSTM). The rest of the code is the same."
      ],
      "metadata": {
        "id": "cfpMTeNQQwK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size, num_hiddens, device = len(vocab), 256, try_gpu()\n",
        "num_epochs, lr = 500, 1\n",
        "\n",
        "num_inputs = vocab_size\n",
        "lstm_layer = nn.LSTM(num_inputs, num_hiddens)\n",
        "model = RNNModel(lstm_layer, len(vocab))\n",
        "model = model.to(device)\n",
        "perplexities = train(model, train_iter, vocab, lr, num_epochs, device) #5 min"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7POaU9GyUax1",
        "outputId": "18980ed2-0ef8-46ab-c346-3b345e44cad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time traveller                                                  \n",
            "time traveller  t t t t t t t t t t t t t t t t t t t t t t t t \n",
            "time traveller ate the te at ate the te at ate the te at ate the\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time travellere the the the the the the the the the the the the \n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time travellerererererererererererererererererererererererererer\n",
            "time travellerererererererererererererererererererererererererer\n",
            "time traveller and and the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the thing the thing the time the time the time th\n",
            "time traveller the time time tion is a sou the time traveller th\n",
            "time traveller the thing the thee the tree the thing the thee th\n",
            "time traveller the thing the time traveller the time traveller t\n",
            "time traveller the time traveller the time traveller the time tr\n",
            "time traveller the thing the medint of space the time traveller \n",
            "time traveller the dimensions of space the time traveller the di\n",
            "time traveller thing the time traveller thing the time traveller\n",
            "time traveller of the three dimension at in asmint and menthat i\n",
            "time traveller thing the time traveller thing the time traveller\n",
            "time traveller whou thee ourmals haid and said the mery young ma\n",
            "time traveller whe gother dimensions of space and a fourth trave\n",
            "time traveller cur lanes eereare the gryorid dimensins fortand t\n",
            "time traveller thing the time travellerit would be remardeby con\n",
            "time traveller momeno betho kees of specinct ancestions of space\n",
            "time traveller comend betree tome so igwines they ienas it yow y\n",
            "time traveller wot s atwing of the frech oflemithe overid the co\n",
            "time traveller wull pas it we mat bat mave about in time for ins\n",
            "time traveller wut sow it wo conce for indthen whor said the med\n",
            "time traveller wotle thas a mantly aracled as rearthe is alay of\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller wome the ramth indinfforet ton gemer upon in in a\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller with a slight accession ofcheerfulness really thi\n",
            "time traveller with a slight accession ofcheerfulness really thi\n",
            "time traveller his sowhired existance herng we are andins to spa\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller with a slight accession ofcheerfulness really thi\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller for some than a saligttyccilly in a lare of had i\n",
            "perplexity 1.1, device cpu\n",
            "time traveller for some than a saligttyccilly in a lare of had i\n",
            "travelleryou can show black is white by argument said filby\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We again plot the perplexity during training."
      ],
      "metadata": {
        "id": "_w4YCS9PREfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_perplexity(perplexities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoDQOjHjVMMl",
        "outputId": "9ded93b0-238e-438d-c0da-903b2e97b649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deep recurrent neural networks"
      ],
      "metadata": {
        "id": "xBhUSAeQU3Na"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fortunately, many of the logistical details required to implement multiple layers of an RNN are readily available in high-level APIs. To keep things simple, we only illustrate the implementation using such built-in functionalities. Let us take an LSTM model as an example. The code is very similar to the one we used previously. In fact, the only difference is that we specify the number of layers explicitly, rather than picking the default of a single layer.\n",
        "\n",
        "The architectural decisions such as choosing hyperparameters are very similar to those we saw before. We pick the same number of inputs and outputs as we have distinct tokens, i.e., `vocab_size`. The number of hidden units is still $256$. The only difference is that we now select a nontrivial number of hidden layers by specifying the value of `num_layers`.\n",
        "\n",
        "Since now we instantiate two layers with the LSTM model, this rather more complex architecture slows down training considerably."
      ],
      "metadata": {
        "id": "fLtD8ft7Rd28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size, num_hiddens, num_layers, device = len(vocab), 256, 2, try_gpu()\n",
        "num_epochs, lr = 500, 2\n",
        "\n",
        "num_inputs = vocab_size\n",
        "lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers)\n",
        "model = RNNModel(lstm_layer, len(vocab))\n",
        "model = model.to(device)\n",
        "perplexities = train(model, train_iter, vocab, lr, num_epochs, device) #11 min"
      ],
      "metadata": {
        "id": "ofYvVBA-U9ZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4dea002-27a6-41d9-f9f2-63242f208086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time traveller                                                  \n",
            "time traveller                                                  \n",
            "time traveller tate tate tate tate tate tate tate tate tate tate\n",
            "time traveller ta ae te ae te ae te ae te ae te ae te ae te ae t\n",
            "time traveller the te te te te te te te te te te te te te te te \n",
            "time travellere the the the the the the the the the the the the \n",
            "time travellere the the the the the the the the the the the the \n",
            "time travellerenthent ant ant ant ant ant ant ant ant ant ant an\n",
            "time travellerererererererererererererererererererererererererer\n",
            "time traveller an a the the the the the the the the the the the \n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the there and the time traveller the there and th\n",
            "time traveller the the the the the the the the the the the the t\n",
            "time traveller the the than the than the than the than the than \n",
            "time traveller thing thisklouns of the thing thingless of there \n",
            "time traveller that is this a mutter as this a simetter thichthr\n",
            "time traveller the grave dimensions and there are alles the time\n",
            "time traveller the grover three dimensions of space there is to \n",
            "time traveller this that is a fither at the fourth dimension it \n",
            "time travellerit s geal young man thoughtin which case they woul\n",
            "time travellerit s against reason said filby who tay another way\n",
            "time travellerit s against reason said filby but you will soon a\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller but now you begin to seethe object of my investig\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller with a slight accession ofcheerfulness really thi\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time traveller abbut this is a filulithy smim diy couling the ti\n",
            "time traveller for so it will be convenient to speak of himwas e\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time travelleryou can show black is white by argument said filby\n",
            "time travelleryou can show black is white by argument said filby\n",
            "perplexity 1.0, device cpu\n",
            "time travelleryou can show black is white by argument said filby\n",
            "travelleryou can show black is white by argument said filby\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also plot the perplexity during training."
      ],
      "metadata": {
        "id": "WLqrBeDLSHeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_perplexity(perplexities)"
      ],
      "metadata": {
        "id": "kG3gwwcSVM6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea48cdb7-098a-4eaf-e4a8-fd6f05c3396d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sequence to sequence learning"
      ],
      "metadata": {
        "id": "tXcDgcWdVyHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To begin with, we download an English-French dataset that consists of [bilingual sentence pairs from the Tatoeba Project](http://www.manythings.org/anki/). Each line in the dataset is a tab-delimited pair of an English text sequence and the translated French text sequence. Note that each text sequence can be just one sentence or a paragraph of multiple sentences. In this machine translation problem, where English is translated into French, English is the *source language* and French is the *target language*."
      ],
      "metadata": {
        "id": "Nm7jAXGSSbMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_extract(url, folder=None):\n",
        "    \"\"\"Download and extract a zip file.\"\"\"\n",
        "    fname = download(url)\n",
        "    base_dir = os.path.dirname(fname)\n",
        "    data_dir, ext = os.path.splitext(fname)\n",
        "    if ext == '.zip':\n",
        "        fp = zipfile.ZipFile(fname, 'r')\n",
        "    else:\n",
        "        assert False, 'Only zip files can be extracted.'\n",
        "    fp.extractall(base_dir)\n",
        "    return os.path.join(base_dir, folder) if folder else data_dir"
      ],
      "metadata": {
        "id": "yA6Tfn-7WHA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data_nmt():\n",
        "    \"\"\"Load the English-French dataset.\"\"\"\n",
        "    data_dir = download_extract('http://d2l-data.s3-accelerate.amazonaws.com/fra-eng.zip')\n",
        "    with open(os.path.join(data_dir, 'fra.txt'), 'r') as f:\n",
        "        return f.read()\n",
        "\n",
        "raw_text = read_data_nmt()\n",
        "print(raw_text[:75])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS4KTKVzV_pp",
        "outputId": "c3535ce8-4e25-4641-8764-86a3e24b67ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go.\tVa !\n",
            "Hi.\tSalut !\n",
            "Run!\tCours !\n",
            "Run!\tCourez !\n",
            "Who?\tQui ?\n",
            "Wow!\tÇa alors !\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After downloading the dataset, we proceed with several preprocessing steps for the raw text data. For instance, we replace non-breaking space with space, convert uppercase letters to lowercase ones, and insert space between words and punctuation marks."
      ],
      "metadata": {
        "id": "6555m0P1SwmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_nmt(text):\n",
        "    \"\"\"Preprocess the English-French dataset.\"\"\"\n",
        "    def no_space(char, prev_char):\n",
        "        return char in set(',.!?') and prev_char != ' '\n",
        "\n",
        "    # Replace non-breaking space with space, and convert uppercase letters to\n",
        "    # lowercase ones\n",
        "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
        "    # Insert space between words and punctuation marks\n",
        "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
        "           for i, char in enumerate(text)]\n",
        "    return ''.join(out)\n",
        "\n",
        "text = preprocess_nmt(raw_text)\n",
        "print(text[:80])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24pVARcFWcAY",
        "outputId": "e8878667-6d41-4515-8bfd-aea3df043ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "go .\tva !\n",
            "hi .\tsalut !\n",
            "run !\tcours !\n",
            "run !\tcourez !\n",
            "who ?\tqui ?\n",
            "wow !\tça alors !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different from character-level tokenization we saw earlier, for machine translation we prefer word-level tokenization here (state-of-the-art models may use more advanced tokenization techniques). The following `tokenize_nmt()` function tokenizes the the first `num_examples` text sequence pairs, where each token is either a word or a punctuation mark. This function returns two lists of token lists: `source` and `target`. Specifically, `source[i]` is a list of tokens from the $i$th text sequence in the source language (English here) and `target[i]` is that in the target language (French here)."
      ],
      "metadata": {
        "id": "fJY3da_IS88V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_nmt(text, num_examples=None):\n",
        "    \"\"\"Tokenize the English-French dataset.\"\"\"\n",
        "    source, target = [], []\n",
        "    for i, line in enumerate(text.split('\\n')):\n",
        "        if num_examples and i > num_examples:\n",
        "            break\n",
        "        parts = line.split('\\t')\n",
        "        if len(parts) == 2:\n",
        "            source.append(parts[0].split(' '))\n",
        "            target.append(parts[1].split(' '))\n",
        "    return source, target\n",
        "\n",
        "source, target = tokenize_nmt(text)\n",
        "source[:6], target[:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8vc7x_KXAIL",
        "outputId": "ec1ba8f5-d76c-40a2-e5c4-026faef7c810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['go', '.'],\n",
              "  ['hi', '.'],\n",
              "  ['run', '!'],\n",
              "  ['run', '!'],\n",
              "  ['who', '?'],\n",
              "  ['wow', '!']],\n",
              " [['va', '!'],\n",
              "  ['salut', '!'],\n",
              "  ['cours', '!'],\n",
              "  ['courez', '!'],\n",
              "  ['qui', '?'],\n",
              "  ['ça', 'alors', '!']])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us plot the histogram of the number of tokens per text sequence. In this simple English-French dataset, most of the text sequences have fewer than $20$ tokens."
      ],
      "metadata": {
        "id": "S8F1Qs-hTX61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist):\n",
        "    \"\"\"Plot the histogram for list length pairs.\"\"\"\n",
        "    _, _, patches = plt.hist(\n",
        "        [[len(l) for l in xlist], [len(l) for l in ylist]])\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    for patch in patches[1].patches:\n",
        "        patch.set_hatch('/')\n",
        "    plt.legend(legend)\n",
        "\n",
        "show_list_len_pair_hist(['source', 'target'], '# tokens per sequence',\n",
        "                        'count', source, target);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU8stmpoXDpt",
        "outputId": "3c84f1bf-cf33-48cd-a5ac-9fee5b9e113c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the machine translation dataset consists of pairs of languages, we can build two vocabularies for both the source language and the target language separately. With word-level tokenization, the vocabulary size will be significantly larger than that using character-level tokenization. To alleviate this, here we treat infrequent tokens that appear less than $2$ times as the same unknown (\"&lt;unk&gt;\") token. Besides that, we specify additional special tokens such as for padding (\"&lt;pad&gt;\") sequences to the same length in mini-batches, and for marking the beginning (\"&lt;bos&gt;\") or end (\"&lt;eos&gt;\") of sequences. Such special tokens are commonly used in natural language processing tasks."
      ],
      "metadata": {
        "id": "dNhFRR5KTjay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = Vocab(source, min_freq=2,\n",
        "                  reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
        "len(src_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xweCSQpSXSYI",
        "outputId": "54bc3d7c-242c-4162-ac89-be79d68ac0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10012"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that, in language modeling, each sequence example, either a segment of one sentence or a span over multiple sentences, has a fixed length. This was specified by the `num_steps` (number of time steps or tokens) argument. In machine translation, each example is a pair of source and target text sequences, where each text sequence may have different lengths.\n",
        "\n",
        "For computational efficiency, we can still process a mini-batch of text sequences at one time by *truncation* and *padding*. Suppose that every sequence in the same mini-batch should have the same length `num_steps`. If a text sequence has fewer than `num_steps` tokens, we will keep appending the special \"&lt;pad&gt;\" token to its end, until its length reaches `num_steps`. Otherwise, we will truncate the text sequence by only taking its first `num_steps` tokens and discarding the remaining. In this way, every text sequence will have the same length to be loaded in mini-batches of the same shape.\n",
        "\n",
        "The following `truncate_pad()` function truncates or pads text sequences, as described before."
      ],
      "metadata": {
        "id": "ywnQYKydUCGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def truncate_pad(line, num_steps, padding_token):\n",
        "    \"\"\"Truncate or pad sequences.\"\"\"\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps]  # Truncate\n",
        "    return line + [padding_token] * (num_steps - len(line))  # Pad\n",
        "\n",
        "truncate_pad(src_vocab[source[0]], 10, src_vocab['<pad>'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ_jJ8CtXYYC",
        "outputId": "e0848cb1-bc65-4a52-bef8-c82019d27826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[47, 4, 1, 1, 1, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we define a function to transform text sequences into mini-batches for training. We append the special “&lt;eos&gt;” token to the end of every sequence to indicate the end of the sequence. When a model is predicting by generating a sequence token after token, the generation of the “&lt;eos&gt;” token can suggest that the output sequence is complete. Besides, we also record the length of each text sequence excluding the padding tokens. This information will be needed by some models that we will cover later."
      ],
      "metadata": {
        "id": "NQTcy_hGU3EM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_array_nmt(lines, vocab, num_steps):\n",
        "    \"\"\"Transform text sequences of machine translation into mini-batches.\"\"\"\n",
        "    lines = [vocab[l] for l in lines]\n",
        "    lines = [l + [vocab['<eos>']] for l in lines]\n",
        "    array = torch.tensor([truncate_pad(\n",
        "        l, num_steps, vocab['<pad>']) for l in lines])\n",
        "    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
        "    return array, valid_len"
      ],
      "metadata": {
        "id": "tPXINzqCXcU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we define the `load_data_nmt()` function to return the data iterator, together with the vocabularies for both the source language and the target language."
      ],
      "metadata": {
        "id": "oyrG4eWrVOxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_array(data_arrays, batch_size, is_train=True):\n",
        "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
        "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)"
      ],
      "metadata": {
        "id": "S1DUstqJcNtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
        "    \"\"\"Return the iterator and the vocabularies of the translation dataset.\"\"\"\n",
        "    text = preprocess_nmt(read_data_nmt())\n",
        "    source, target = tokenize_nmt(text, num_examples)\n",
        "    src_vocab = Vocab(source, min_freq=2,\n",
        "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
        "    tgt_vocab = Vocab(target, min_freq=2,\n",
        "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
        "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
        "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
        "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
        "    data_iter = load_array(data_arrays, batch_size)\n",
        "    return data_iter, src_vocab, tgt_vocab"
      ],
      "metadata": {
        "id": "uZvLIhV9Xebd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us read the first mini-batch from the English-French dataset."
      ],
      "metadata": {
        "id": "WJEUZ0gVVWRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size=2, num_steps=8)\n",
        "for X, X_valid_len, Y, Y_valid_len in train_iter:\n",
        "    print('X:', X.type(torch.int32))\n",
        "    print('valid lengths for X:', X_valid_len)\n",
        "    print('Y:', Y.type(torch.int32))\n",
        "    print('valid lengths for Y:', Y_valid_len)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqQOYcV3c3Zh",
        "outputId": "d465b805-dd57-403c-9e7b-e4ccf7695e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: tensor([[ 7, 35,  4,  3,  1,  1,  1,  1],\n",
            "        [39, 81,  4,  3,  1,  1,  1,  1]], dtype=torch.int32)\n",
            "valid lengths for X: tensor([4, 4])\n",
            "Y: tensor([[ 6,  7, 85,  4,  3,  1,  1,  1],\n",
            "        [ 0,  4,  3,  1,  1,  1,  1,  1]], dtype=torch.int32)\n",
            "valid lengths for Y: tensor([5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine translation is a major problem domain for sequence transduction models, whose input and output are both variable-length sequences. To handle this type of inputs and outputs, we can design an architecture with two major components.\n",
        "The first component is an *encoder*: it takes a variable-length sequence as the input and transforms it into a state with a fixed shape. The second component is a *decoder*: it maps the encoded state of a fixed shape to a variable-length sequence. This is called an *encoder-decoder* architecture.\n",
        "\n",
        "Since the encoder-decoder architecture forms the basis of different sequence transduction models, we will first convert this architecture into an interface that will be implemented later.\n",
        "\n",
        "In the encoder interface, we just specify that the encoder takes variable-length sequences as the input `X`. The implementation will be provided\n",
        "by any model that inherits this base `Encoder` class."
      ],
      "metadata": {
        "id": "GMnkYnplVn1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"The base encoder interface for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "\n",
        "    def forward(self, X, *args):\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "mNj0l5WYdCyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following decoder interface, we add an additional `init_state()` function\n",
        "to convert the encoder output (`enc_outputs`) into the encoded state. Note that this step may need extra inputs, such as the valid length of the input, which was explained before. To generate a variable-length sequence token by token, every time the decoder may map an input (e.g., the generated token at the previous time step) and the encoded state into an output token at the current time step."
      ],
      "metadata": {
        "id": "REv9S3cKWOFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"The base decoder interface for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Decoder, self).__init__(**kwargs)\n",
        "\n",
        "    def init_state(self, enc_outputs, *args):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "AcGnDak2dFER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the end, the encoder-decoder architecture contains both an encoder and a decoder, with optionally extra arguments. In the forward propagation, the output of the encoder is used to produce the encoded state, and this state will be further used by the decoder as one of its inputs."
      ],
      "metadata": {
        "id": "Xe00v7s1WkMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"The base class for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(EncoderDecoder, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, enc_X, dec_X, *args):\n",
        "        enc_outputs = self.encoder(enc_X, *args)\n",
        "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
        "        return self.decoder(dec_X, dec_state)"
      ],
      "metadata": {
        "id": "fSBEOYucdHK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will use two RNNs to design the encoder and the decoder of this architecture and apply it to *sequence to sequence* learning for machine translation.\n",
        "\n",
        "Let us first implement the RNN encoder. Note that we use an *embedding layer* to obtain the feature vector for each token in the input sequence. The weight of an embedding layer is a matrix whose number of rows equals the size of the input vocabulary (`vocab_size`) and number of columns equals the feature vector's dimension (`embed_size`). For any input token index $i$, the embedding layer fetches the $i$th row (starting from $0$) of the weight matrix to return its feature vector. Besides, here we choose a multilayer GRU to implement the encoder."
      ],
      "metadata": {
        "id": "v2uuP_goW6bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqEncoder(Encoder):\n",
        "    \"\"\"The RNN encoder for sequence to sequence learning.\"\"\"\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
        "                 dropout=0, **kwargs):\n",
        "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,\n",
        "                          dropout=dropout)\n",
        "\n",
        "    def forward(self, X, *args):\n",
        "        # The output `X` shape: (`batch_size`, `num_steps`, `embed_size`)\n",
        "        X = self.embedding(X)\n",
        "        # In RNN models, the first axis corresponds to time steps\n",
        "        X = X.permute(1, 0, 2)\n",
        "        # When state is not mentioned, it defaults to zeros\n",
        "        output, state = self.rnn(X)\n",
        "        # `output` shape: (`num_steps`, `batch_size`, `num_hiddens`)\n",
        "        # `state` shape: (`num_layers`, `batch_size`, `num_hiddens`)\n",
        "        return output, state"
      ],
      "metadata": {
        "id": "6gCMPzLLdc40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us use a concrete example to illustrate the above encoder implementation. Below we instantiate a two-layer GRU encoder whose number of hidden units is $16$. Given a mini-batch of sequence inputs `X` (batch size: $4$, number of time steps: $7$), the hidden states of the last layer at all the time steps (`output` return by the encoder's recurrent layers) are a tensor of shape (number of time steps, batch size, number of hidden units)."
      ],
      "metadata": {
        "id": "LUX92tZAXphk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
        "                         num_layers=2)\n",
        "encoder.eval()\n",
        "X = torch.zeros((4, 7), dtype=torch.long)\n",
        "output, state = encoder(X)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vjAYeIMdfoY",
        "outputId": "21e405d8-1740-4fb6-c742-c25867371d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7, 4, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since a GRU is employed here, the shape of the multilayer hidden states at the final time step is (number of hidden layers, batch size, number of hidden units). If an LSTM is used, memory cell information will also be contained in `state`."
      ],
      "metadata": {
        "id": "aRkKWmiWYHlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4KQM_iTdhtt",
        "outputId": "68396125-8572-4419-a56c-6b228d83ba98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When implementing the decoder as follows, we directly use the hidden state at the final time step of the encoder to initialize the hidden state of the decoder. This requires that the RNN encoder and the RNN decoder have the same number of layers and hidden units. To further incorporate the encoded input sequence information, the context variable is concatenated with the decoder input at all the time steps. To predict the probability distribution of the output token, a fully-connected layer is used to transform the hidden state at the final layer of the RNN decoder."
      ],
      "metadata": {
        "id": "fAajv66GYUuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqDecoder(Decoder):\n",
        "    \"\"\"The RNN decoder for sequence to sequence learning.\"\"\"\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
        "                 dropout=0, **kwargs):\n",
        "        super(Seq2SeqDecoder, self).__init__(**kwargs)\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,\n",
        "                          dropout=dropout)\n",
        "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
        "\n",
        "    def init_state(self, enc_outputs, *args):\n",
        "        return enc_outputs[1]\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        # The output `X` shape: (`num_steps`, `batch_size`, `embed_size`)\n",
        "        X = self.embedding(X).permute(1, 0, 2)\n",
        "        # Broadcast `context` so it has the same `num_steps` as `X`\n",
        "        context = state[-1].repeat(X.shape[0], 1, 1)\n",
        "        X_and_context = torch.cat((X, context), 2)\n",
        "        output, state = self.rnn(X_and_context, state)\n",
        "        output = self.dense(output).permute(1, 0, 2)\n",
        "        # `output` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
        "        # `state` shape: (`num_layers`, `batch_size`, `num_hiddens`)\n",
        "        return output, state"
      ],
      "metadata": {
        "id": "VEJSgjFIdkYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To illustrate the implemented decoder, below we instantiate it with the same hyperparameters from the aforementioned encoder. As we can see, the output shape of the decoder becomes (batch size, number of time steps, vocabulary size), where the last dimension of the tensor stores the predicted token distribution."
      ],
      "metadata": {
        "id": "U97qXssJYl7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
        "                         num_layers=2)\n",
        "decoder.eval()\n",
        "state = decoder.init_state(encoder(X))\n",
        "output, state = decoder(X, state)\n",
        "output.shape, state.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyLWKXyFdm2g",
        "outputId": "1a02ddc9-901c-4213-9b77-58d14c63d6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 7, 10]), torch.Size([2, 4, 16]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At each time step, the decoder predicts a probability distribution for the output tokens. Similar to language modeling, we can apply softmax to obtain the distribution and calculate the cross-entropy loss for optimization. Recall that the special padding tokens are appended to the end of sequences, so sequences of varying lengths can be efficiently loaded in mini-batches of the same shape. However, prediction of padding tokens should be excluded from loss calculations.\n",
        "\n",
        "To this end, we can use the following `sequence_mask()` function to mask irrelevant entries with zero values, so later multiplication of any irrelevant prediction with zero equals to zero. For example, if the valid length of two sequences excluding padding tokens are one and two, respectively, the remaining entries after the first one and the first two entries are cleared to zeros."
      ],
      "metadata": {
        "id": "Rst8LFfCY1Mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_mask(X, valid_len, value=0):\n",
        "    \"\"\"Mask irrelevant entries in sequences.\"\"\"\n",
        "    maxlen = X.size(1)\n",
        "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
        "                        device=X.device)[None, :] < valid_len[:, None]\n",
        "    X[~mask] = value\n",
        "    return X\n",
        "\n",
        "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "sequence_mask(X, torch.tensor([1, 2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L-SOktBdpRd",
        "outputId": "ddc38bfa-e7c0-42c5-ef9e-d98192e3adea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0, 0],\n",
              "        [4, 5, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also mask all the entries across the last few axes. If we want, we may even specify to replace such entries with a non-zero value."
      ],
      "metadata": {
        "id": "Mfy0s7aDZW-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones(2, 3, 4)\n",
        "sequence_mask(X, torch.tensor([1, 2]), value=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aijm-Vcbdrv3",
        "outputId": "09ee1949-6fbf-4dcf-d79e-459bf0bb4bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.,  1.,  1.,  1.],\n",
              "         [-1., -1., -1., -1.],\n",
              "         [-1., -1., -1., -1.]],\n",
              "\n",
              "        [[ 1.,  1.,  1.,  1.],\n",
              "         [ 1.,  1.,  1.,  1.],\n",
              "         [-1., -1., -1., -1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can extend the softmax cross-entropy loss to allow the masking of irrelevant predictions. Initially, masks for all the predicted tokens are set to one. Once the valid length is given, the mask corresponding to any padding token will be cleared to zero. In the end, the loss for all the tokens will be multipled by the mask to filter out irrelevant predictions of padding tokens in the loss."
      ],
      "metadata": {
        "id": "uqnaIdlAZhTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
        "    \"\"\"The softmax cross-entropy loss with masks.\"\"\"\n",
        "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
        "    # `label` shape: (`batch_size`, `num_steps`)\n",
        "    # `valid_len` shape: (`batch_size`,)\n",
        "    def forward(self, pred, label, valid_len):\n",
        "        weights = torch.ones_like(label)\n",
        "        weights = sequence_mask(weights, valid_len)\n",
        "        self.reduction='none'\n",
        "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
        "            pred.permute(0, 2, 1), label)\n",
        "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
        "        return weighted_loss"
      ],
      "metadata": {
        "id": "1crTZBp8duev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a sanity check, we can create three identical sequences. Then, we can specify that the valid lengths of these sequences are $4$, $2$, and $0$, respectively. As a result, the loss of the first sequence should be twice as large as that of the second sequence, while the third sequence should have a zero loss."
      ],
      "metadata": {
        "id": "RFFU9b3BZzPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = MaskedSoftmaxCELoss()\n",
        "loss(torch.ones(3, 4, 10), torch.ones((3, 4), dtype=torch.long),\n",
        "     torch.tensor([4, 2, 0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwaTJaG0dwTp",
        "outputId": "49878c75-1f6c-4038-8829-1db65f99f746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.3026, 1.1513, 0.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following training loop, we concatenate the special beginning-of-sequence token and the original output sequence, excluding the final token, as the input to the decoder. This is called *teacher forcing*, because the original output sequence (token labels) is fed into the decoder. Alternatively, we could also feed the *predicted* token from the previous time step as the current input to the decoder."
      ],
      "metadata": {
        "id": "JtFc28G7Z_3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
        "    \"\"\"Train a model for sequence to sequence.\"\"\"\n",
        "    def xavier_init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "        if type(m) == nn.GRU:\n",
        "            for param in m._flat_weights_names:\n",
        "                if \"weight\" in param:\n",
        "                    nn.init.xavier_uniform_(m._parameters[param])\n",
        "    net.apply(xavier_init_weights)\n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    loss = MaskedSoftmaxCELoss()\n",
        "    net.train()\n",
        "    train_loss_all = []\n",
        "    for epoch in range(num_epochs):\n",
        "        # Sum of training loss, no. of tokens\n",
        "        total_loss = 0\n",
        "        total_tokens = 0\n",
        "        for batch in data_iter:\n",
        "            optimizer.zero_grad()\n",
        "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
        "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
        "                               device=device).reshape(-1, 1)\n",
        "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
        "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
        "            l = loss(Y_hat, Y, Y_valid_len)\n",
        "            l.sum().backward()  # Make the loss scalar for `backward`\n",
        "            grad_clipping(net, 1)\n",
        "            num_tokens = Y_valid_len.sum()\n",
        "            optimizer.step()\n",
        "            with torch.no_grad():\n",
        "                total_loss += l.sum()\n",
        "                total_tokens += num_tokens\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            train_loss_all.append(total_loss / total_tokens)\n",
        "    print(f'loss {total_loss / total_tokens:.3f}, device {str(device)}')\n",
        "\n",
        "    return train_loss_all"
      ],
      "metadata": {
        "id": "_NzEE6Dbdz9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can create and train an RNN encoder-decoder model for sequence to sequence learning on the machine translation dataset."
      ],
      "metadata": {
        "id": "Wx1VWsWPaX3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
        "batch_size, num_steps = 64, 10\n",
        "lr, num_epochs, device = 0.005, 300, try_gpu()\n",
        "\n",
        "train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size, num_steps)\n",
        "encoder = Seq2SeqEncoder(\n",
        "    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
        "decoder = Seq2SeqDecoder(\n",
        "    len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
        "net = EncoderDecoder(encoder, decoder)\n",
        "train_loss_all = train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device) #1 min"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv8JuTTvfgnT",
        "outputId": "07e5a9da-faed-49f1-adf9-8ae5dc9ddb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.019, device cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We plot the loss during training using the `plot_loss()` function."
      ],
      "metadata": {
        "id": "pnLV65Cpallv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(train_loss_all):\n",
        "    epochs = range(10, len(train_loss_all * 10) + 1, 10)\n",
        "    plt.plot(epochs, train_loss_all, 'b', label='Train loss')\n",
        "    plt.title('Training loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NLYXSNfgfJZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(train_loss_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfXU2YXPgBjL",
        "outputId": "99dc2c13-86b7-41de-e53c-92b15fabf282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To predict the output sequence token by token, at each decoder time step, the predicted token from the previous time step is fed into the decoder as an input.\n",
        "Similar to training, at the initial time step, the beginning-of-sequence (\"&lt;bos&gt;\") token is fed into the decoder. When the end-of-sequence (\"&lt;eos&gt;\") token is predicted, the prediction of the output sequence is complete."
      ],
      "metadata": {
        "id": "3SeUF2pKain4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
        "                    device, save_attention_weights=False):\n",
        "    \"\"\"Predict for sequence to sequence.\"\"\"\n",
        "    # Set `net` to eval mode for inference\n",
        "    net.eval()\n",
        "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
        "        src_vocab['<eos>']]\n",
        "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
        "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
        "    # Add the batch axis\n",
        "    enc_X = torch.unsqueeze(\n",
        "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
        "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
        "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
        "    # Add the batch axis\n",
        "    dec_X = torch.unsqueeze(torch.tensor(\n",
        "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
        "    output_seq, attention_weight_seq = [], []\n",
        "    for _ in range(num_steps):\n",
        "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
        "        # We use the token with the highest prediction likelihood as the input\n",
        "        # of the decoder at the next time step\n",
        "        dec_X = Y.argmax(dim=2)\n",
        "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
        "        # Save attention weights\n",
        "        if save_attention_weights:\n",
        "            attention_weight_seq.append(net.decoder.attention_weights)\n",
        "        # Once the end-of-sequence token is predicted, the generation of the\n",
        "        # output sequence is complete\n",
        "        if pred == tgt_vocab['<eos>']:\n",
        "            break\n",
        "        output_seq.append(pred)\n",
        "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
      ],
      "metadata": {
        "id": "-1u4n4GhgL8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can evaluate a predicted sequence by comparing it with the label sequence (the ground-truth). BLEU (Bilingual Evaluation Understudy), though originally proposed for evaluating machine translation results, has been extensively used in measuring the quality of output sequences for different applications. In principle, for any $n$-grams in the predicted sequence, BLEU evaluates whether this $n$-grams appears in the label sequence.\n",
        "\n",
        "We implement the BLEU measure as follows."
      ],
      "metadata": {
        "id": "Mp-6ywT2bJkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bleu(pred_seq, label_seq, k):\n",
        "    \"\"\"Compute the BLEU.\"\"\"\n",
        "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
        "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
        "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
        "    for n in range(1, k + 1):\n",
        "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
        "        for i in range(len_label - n + 1):\n",
        "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
        "        for i in range(len_pred - n + 1):\n",
        "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
        "                num_matches += 1\n",
        "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
        "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
        "    return score"
      ],
      "metadata": {
        "id": "7xWGTh76gRVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the end, we use the trained RNN encoder-decoder to translate a few English sentences into French and compute the BLEU of the results."
      ],
      "metadata": {
        "id": "daNd9-vLbbvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
        "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
        "for eng, fra in zip(engs, fras):\n",
        "    translation, attention_weight_seq = predict_seq2seq(\n",
        "        net, eng, src_vocab, tgt_vocab, num_steps, device)\n",
        "    print(f'{eng} => {translation}, bleu {bleu(translation, fra, k=2):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh5KBMtngURW",
        "outputId": "6f430d39-a929-4804-c060-7de276159060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "go . => va <unk> ., bleu 0.000\n",
            "i lost . => j'ai perdu ., bleu 1.000\n",
            "he's calm . => il est <unk> <unk> ., bleu 0.548\n",
            "i'm home . => je suis malade ., bleu 0.512\n"
          ]
        }
      ]
    }
  ]
}